import streamlit as st
import requests
import json
import plotly.graph_objects as go
import time

# ××™×œ×•×Ÿ ×ª×¨×’×•× ×•×”×’×“×¨×•×ª ×‘×¡×™×¡
TRAIT_DICT = {
    "Honesty-Humility": "×›× ×•×ª ×•×¢× ×•×•×” (H)",
    "Emotionality": "×¨×’×©×™×•×ª (E)",
    "Extraversion": "××•×—×¦× ×•×ª (X)",
    "Agreeableness": "× ×¢×™××•×ª (A)",
    "Conscientiousness": "××¦×¤×•× ×™×•×ª (C)",
    "Openness to Experience": "×¤×ª×™×—×•×ª (O)"
}

IDEAL_DOCTOR = {
    "Honesty-Humility": 4.55, 
    "Emotionality": 3.85, 
    "Extraversion": 3.9,
    "Agreeableness": 4.3, 
    "Conscientiousness": 4.55, 
    "Openness to Experience": 3.8
}

# ×”×’×“×¨×ª ×˜×•×•×—×™× ×§×¨×™×˜×™×™× ×œ×›×œ ×ª×›×•× ×”
TRAIT_RANGES = {
    "Honesty-Humility": {"critical_low": 3.5, "optimal_low": 4.2, "optimal_high": 4.9, "critical_high": 5.0},
    "Emotionality": {"critical_low": 2.8, "optimal_low": 3.6, "optimal_high": 4.1, "critical_high": 4.5},
    "Extraversion": {"critical_low": 2.5, "optimal_low": 3.6, "optimal_high": 4.2, "critical_high": 4.8},
    "Agreeableness": {"critical_low": 3.2, "optimal_low": 4.0, "optimal_high": 4.6, "critical_high": 5.0},
    "Conscientiousness": {"critical_low": 3.8, "optimal_low": 4.3, "optimal_high": 4.8, "critical_high": 5.0},
    "Openness to Experience": {"critical_low": 2.8, "optimal_low": 3.5, "optimal_high": 4.1, "critical_high": 4.7}
}

class HEXACO_Analyzer:
    def __init__(self):
        # ×˜×¢×™× ×ª ×”××¤×ª×—×•×ª ××”-Secrets
        self.gemini_keys = [
            st.secrets.get("GEMINI_KEY_1", "").strip(),
            st.secrets.get("GEMINI_KEY_2", "").strip(),
            st.secrets.get("GEMINI_KEY_3", "").strip()  # ×ª××™×›×” ×‘××¤×ª×— × ×•×¡×£
        ]
        self.gemini_keys = [k for k in self.gemini_keys if k]
        self.claude_key = st.secrets.get("CLAUDE_KEY", "").strip()

    def _discover_gemini_model(self, api_key):
        """×’×™×œ×•×™ ××•×˜×•××˜×™ ×©×œ ××•×“×œ Gemini ×”×˜×•×‘ ×‘×™×•×ª×¨"""
        default_model = "models/gemini-1.5-flash-latest"
        if not api_key: return default_model
        list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
        try:
            res = requests.get(list_url, timeout=7)
            if res.status_code == 200:
                models_data = res.json().get("models", [])
                # ×—×™×¤×•×© Pro ×ª×—×™×œ×”, ××—×¨ ×›×š Flash
                pro_models = [str(m["name"]) for m in models_data if isinstance(m.get("name"), str) and "pro" in m["name"].lower()]
                if pro_models: return pro_models[-1]
                flash_models = [str(m["name"]) for m in models_data if isinstance(m.get("name"), str) and "flash" in m["name"].lower()]
                if flash_models: return flash_models[-1]
        except Exception as e:
            st.warning(f"âš ï¸ ×’×™×œ×•×™ ××•×“×œ Gemini × ×›×©×œ: {str(e)}")
        return default_model

    def _discover_claude_model(self):
        """×’×™×œ×•×™ ××•×˜×•××˜×™ ×©×œ ××•×“×œ Claude ×”×¢×“×›× ×™"""
        default_model = "claude-3-5-sonnet-20241022"
        if not self.claude_key: return default_model
        try:
            url = "https://api.anthropic.com/v1/models"
            headers = {"x-api-key": self.claude_key, "anthropic-version": "2023-06-01"}
            res = requests.get(url, headers=headers, timeout=7)
            if res.status_code == 200:
                sonnet_models = [m["id"] for m in res.json().get("data", []) if "sonnet" in m["id"].lower()]
                if sonnet_models: return sorted(sonnet_models)[-1]
        except Exception as e:
            st.warning(f"âš ï¸ ×’×™×œ×•×™ ××•×“×œ Claude × ×›×©×œ: {str(e)}")
        return default_model

    def _build_enhanced_prompt(self, user_name, current_results, history, provider="gemini"):
        """×‘× ×™×™×ª ×¤×¨×•××¤×˜ ××ª×§×“× ×•××¤×•×¨×˜ ×œ× ×™×ª×•×— ×¤×¡×™×›×•×œ×•×’×™ ×¢××•×§"""
        
        # × ×™×ª×•×— ××’××•×ª ×•×”×™×¡×˜×•×¨×™×”
        history_analysis = ""
        if history and isinstance(history, list) and len(history) > 0:
            history_analysis = "\n### ğŸ“Š × ×™×ª×•×— ××’××•×ª ×”×™×¡×˜×•×¨×™×•×ª:\n"
            for idx, h in enumerate(history[:3], 1):
                results_data = h.get('results', {})
                test_date = h.get('test_date', '×œ× ×™×“×•×¢')
                history_analysis += f"\n**××‘×—×Ÿ #{idx} ({test_date}):**\n"
                for trait, score in results_data.items():
                    history_analysis += f"  - {trait}: {score}\n"
            
            # ×—×™×©×•×‘ ×©×™× ×•×™×™×
            if len(history) >= 2:
                history_analysis += "\n**×©×™× ×•×™×™× ××”××‘×—×Ÿ ×”×§×•×“×:**\n"
                prev_results = history[0].get('results', {})
                for trait in current_results:
                    if trait in prev_results:
                        change = current_results[trait] - prev_results[trait]
                        direction = "ğŸ“ˆ" if change > 0 else "ğŸ“‰" if change < 0 else "â¡ï¸"
                        history_analysis += f"  {direction} {trait}: {change:+.2f}\n"

        # × ×™×ª×•×— ×¤×¢×¨×™× ×§×¨×™×˜×™×™×
        gap_analysis = "\n### âš ï¸ × ×™×ª×•×— ×¤×¢×¨×™× ×•××–×•×¨×™ ×¡×™×›×•×Ÿ:\n"
        for trait, score in current_results.items():
            if trait in TRAIT_RANGES:
                ranges = TRAIT_RANGES[trait]
                ideal = IDEAL_DOCTOR[trait]
                gap = score - ideal
                
                if score < ranges["critical_low"]:
                    gap_analysis += f"ğŸ”´ **{trait}**: ×¦×™×•×Ÿ ×§×¨×™×˜×™ × ××•×š ({score:.2f}) - ×¤×¢×¨ ×©×œ {abs(gap):.2f} ××”××™×“×™××œ!\n"
                elif score < ranges["optimal_low"]:
                    gap_analysis += f"ğŸŸ¡ **{trait}**: ××ª×—×ª ×œ×˜×•×•×— ({score:.2f}) - ×¦×¨×™×š ×©×™×¤×•×¨ ×©×œ {abs(gap):.2f}\n"
                elif score > ranges["critical_high"]:
                    gap_analysis += f"ğŸ”´ **{trait}**: ×¦×™×•×Ÿ ×’×‘×•×” ×—×©×•×“ ({score:.2f}) - ×—×©×“ ×œ×¨×™×¦×•×™ ×—×‘×¨×ª×™!\n"
                elif score > ranges["optimal_high"]:
                    gap_analysis += f"ğŸŸ¡ **{trait}**: ××¢×œ ×”×˜×•×•×— ({score:.2f}) - ×™×ª×¨×•×Ÿ ×©×œ {gap:.2f} ××š ×¦×¨×™×š ××™×–×•×Ÿ\n"
                else:
                    gap_analysis += f"âœ… **{trait}**: ×‘×˜×•×•×— ××™×“×™××œ×™ ({score:.2f})\n"

        # ×‘× ×™×™×ª ×”×¤×¨×•××¤×˜ ×”××œ×
        if provider == "gemini":
            prompt = f"""
# ğŸ¯ × ×™×ª×•×— ×¤×¡×™×›×•×œ×•×’×™ ××§×¦×•×¢×™ - ××•×¢××“ ×œ×¨×¤×•××”

## ×¤×¨×˜×™ ×”××•×¢××“
- **×©×**: {user_name}
- **×ª××¨×™×š × ×™×ª×•×—**: {time.strftime('%d/%m/%Y %H:%M')}

## ğŸ“ˆ ×ª×•×¦××•×ª ××‘×—×Ÿ × ×•×›×—×™:
{json.dumps(current_results, indent=2, ensure_ascii=False)}

{history_analysis}

{gap_analysis}

## ğŸ“ ×”× ×—×™×•×ª ×œ× ×™×ª×•×— ××§×¦×•×¢×™:

××ª×” ×¤×¡×™×›×•×œ×•×’ ××¨×’×•× ×™ ×‘×›×™×¨ ×‘××¨×›×– ×”×¢×¨×›×” ×œ×¨×¤×•××” (××¡"×¨). ×ª×¤×§×™×“×š ×œ×›×ª×•×‘ ×“×•×— ××¢××™×§ ×•××¤×•×¨×˜.

### ××‘× ×” ×”×“×•×— ×”× ×“×¨×© (×œ×¤×—×•×ª 1200 ××™×œ×™×):

#### 1. **×¡×™×›×•× ×¨××©×•× ×™** (2-3 ×¤×¡×§××•×ª)
   - ×ª××•× ×” ×›×•×œ×œ×ª ×©×œ ×¤×¨×•×¤×™×œ ×”××•×¢××“
   - × ×§×•×“×•×ª ×—×•×–×§×” ××¨×›×–×™×•×ª
   - ××–×•×¨×™ ×“××’×” ×¢×™×§×¨×™×™×

#### 2. **× ×™×ª×•×— ×ª×›×•× ×”-×ª×›×•× ×”** (×¤×¡×§×” ×œ×›×œ ×ª×›×•× ×”):
   ×œ×›×œ ××—×ª ×-6 ×”×ª×›×•× ×•×ª:
   - ×”×©×•×•××” ×œ×¤×¨×•×¤×™×œ ×”××™×“×™××œ×™ ×©×œ ×¨×•×¤×
   - ××©××¢×•×ª ×”×¦×™×•×Ÿ ×‘×”×§×©×¨ ×¨×¤×•××™
   - ×”×©×œ×›×•×ª ×¢×œ ×¢×‘×•×“×” ×§×œ×™× ×™×ª
   - ×“×•×’×××•×ª ×§×•× ×§×¨×˜×™×•×ª ×œ×¡×™×˜×•××¦×™×•×ª ×¨×¤×•××™×•×ª
   - ×× ×™×© ××’××” ××”×”×™×¡×˜×•×¨×™×” - ×”×¡×‘×¨ ××ª ×”××©××¢×•×ª

#### 3. **× ×™×ª×•×— ××™× ×˜×’×¨×˜×™×‘×™** (3-4 ×¤×¡×§××•×ª):
   - ××™×š ×”×ª×›×•× ×•×ª ××©×¤×™×¢×•×ª ×–×• ×¢×œ ×–×•
   - ×¡×™× ×¨×’×™×•×ª ××• ×¡×ª×™×¨×•×ª ×¤× ×™××™×•×ª
   - ×¤×¨×•×¤×™×œ ×”××™×©×™×•×ª ×”×›×•×œ×œ
   - ×”×ª×××” ×œ×ª×¤×§×™×“×™× ×¨×¤×•××™×™× ×©×•× ×™× (×¨×•×¤× ××©×¤×—×”, ×× ×ª×—, ×¤×¡×™×›×™××˜×¨ ×•×›×•')

#### 4. **×–×™×”×•×™ ×“×¤×•×¡×™ ×ª×’×•×‘×” ×—×©×•×“×™×**:
   - ×—×©×“ ×œ×¨×™×¦×•×™ ×—×‘×¨×ª×™ (Social Desirability)
   - ×¢×§×‘×™×•×ª ×”×ª×©×•×‘×•×ª
   - ×¦×™×•× ×™× ×§×™×¦×•× ×™×™× ×—×©×•×“×™×
   - ×“×¤×•×¡×™ ×ª×’×•×‘×” ×œ× ×˜×™×¤×•×¡×™×™×

#### 5. **××’××•×ª ×œ××•×¨×š ×–××Ÿ** (×× ×™×© ×”×™×¡×˜×•×¨×™×”):
   - ×©×™× ×•×™×™× ××©××¢×•×ª×™×™×
   - ×™×¦×™×‘×•×ª ××• ×ª× ×•×“×ª×™×•×ª
   - ×¤×¨×©× ×•×ª ×œ××’××•×ª

#### 6. **×”××œ×¦×•×ª ××¤×•×¨×˜×•×ª ×œ×©×™×¤×•×¨** (5-7 ×”××œ×¦×•×ª):
   - ××¡×˜×¨×˜×’×™×•×ª ×§×•× ×§×¨×˜×™×•×ª ×œ×›×œ × ×§×•×“×ª ×—×•×œ×©×”
   - ×ª×¨×’×™×œ×™× ×•×¤×¢×™×œ×•×™×•×ª ×¡×¤×¦×™×¤×™×•×ª
   - ×¡×¤×¨×™×/××©××‘×™× ××•××œ×¦×™×
   - ×“×¨×›×™ ×”×›× ×” ×œ×¨××™×•×Ÿ ×”×¡×™××•×œ×¦×™×”

#### 7. **×¢×¦×•×ª ×œ×¨××™×•×Ÿ ×¢× ×©×—×§×Ÿ** (3-4 ×¤×¡×§××•×ª):
   - ×ª×¨×—×™×©×™× ×¦×¤×•×™×™×
   - ××œ×›×•×“×•×ª ×œ×”×™×× ×¢ ××”×Ÿ
   - ××™×š ×œ×”×“×’×™×© ×—×•×–×§×•×ª
   - ××™×š ×œ× ×˜×¨×œ ×—×•×œ×©×•×ª

#### 8. **×ª×—×–×™×ª ×•×”××œ×¦×” ×¡×•×¤×™×ª**:
   - ×¡×™×›×•×™×™ ×”×¦×œ×—×” ×‘×§×‘×œ×” (×‘××—×•×–×™×)
   - ×¡×™×›×•×™×™ ×”×¦×œ×—×” ×‘×¨×¤×•××” (××¨×•×š ×˜×•×•×—)
   - ×ª×—×•××™ ×¨×¤×•××” ××•××œ×¦×™×
   - ×”××œ×¦×” ××™×©×™×ª ×¡×•×¤×™×ª

**×¡×’× ×•×Ÿ ×›×ª×™×‘×”**: 
- ×¢×‘×¨×™×ª ×¨×”×•×˜×” ×•×‘×¨×•×¨×”
- ××©×¤×˜×™× ××•×¨×›×‘×™× ××š ×§×¨×™××™×
- ×©×™××•×© ×‘××•× ×—×™× ×¤×¡×™×›×•×œ×•×’×™×™× ××§×¦×•×¢×™×™× (×¢× ×”×¡×‘×¨)
- ×˜×•×Ÿ ×××¤×ª×™ ××š ×™×©×™×¨
- ×“×•×’×××•×ª ×§×•× ×§×¨×˜×™×•×ª ××”×¢×•×œ× ×”×¨×¤×•××™

**××•×¨×š ××™× ×™××œ×™**: 1200 ××™×œ×™× ×‘×¢×‘×¨×™×ª (×œ× ×›×•×œ×œ ×›×•×ª×¨×•×ª)

×”×ª×—×œ ×‘×›×ª×™×‘×ª ×”×“×•×— ×”××œ× ×¢×›×©×™×•:
"""
        else:  # Claude
            prompt = f"""
You are Dr. Rachel Goldstein, a senior clinical psychologist and personality assessment expert specializing in medical school admissions in Israel. You have 20 years of experience evaluating candidates for Israeli medical schools.

## Candidate Profile
- **Name**: {user_name}
- **Assessment Date**: {time.strftime('%d/%m/%Y %H:%M')}

## Current HEXACO Results:
{json.dumps(current_results, indent=2, ensure_ascii=False)}

{history_analysis}

{gap_analysis}

## Your Mission:
Write an exceptionally detailed, clinically rigorous psychological assessment report in Hebrew. This will be used by medical school admissions committees.

## Report Structure (Minimum 1500 words in Hebrew):

### 1. Executive Summary (3 paragraphs)
- Overall personality profile
- Key strengths for medical practice
- Critical areas of concern
- Prediction of interview performance

### 2. Six-Factor Deep Dive (250+ words per trait)
For each HEXACO dimension, provide:

**A. Quantitative Analysis:**
- Current score vs. ideal physician benchmark
- Percentile ranking compared to medical students
- Statistical significance of gaps
- Trend analysis from historical data (if available)

**B. Clinical Interpretation:**
- What this score reveals about cognitive-emotional patterns
- Behavioral manifestations in clinical settings
- Impact on doctor-patient relationships
- Influence on medical decision-making
- Effect on team collaboration

**C. Real-World Scenarios:**
Describe 2-3 specific medical situations where this trait level would:
- Be an asset or liability
- Create challenges
- Require compensation strategies

**D. Developmental Insights:**
- Is this trait stable or malleable?
- Evidence of growth from past assessments
- Realistic potential for improvement

### 3. Integrative Personality Synthesis (400+ words)
- **Configuration Analysis**: How traits interact dynamically
- **Compensatory Mechanisms**: How high scores balance low ones
- **Internal Conflicts**: Contradictions that create stress
- **Specialty Fit**: 
  - Primary Care: [detailed analysis]
  - Surgery: [detailed analysis]
  - Psychiatry: [detailed analysis]
  - Emergency Medicine: [detailed analysis]
  - Pediatrics: [detailed analysis]

### 4. Validity and Response Pattern Analysis (200+ words)
- **Social Desirability Detection**: Evidence of impression management
- **Response Consistency**: Internal contradictions
- **Extreme Responding**: Tendency toward poles
- **Acquiescence Bias**: Agreement tendency
- **Confidence Level**: How much to trust these results (%)

### 5. Longitudinal Trajectory Analysis (if history exists, 200+ words)
- Meaningful changes over time
- Stability vs. volatility
- Context of changes (stress, preparation, authentic growth?)
- Predictions for future development

### 6. Evidence-Based Development Plan (500+ words)

For each weakness identified, provide:
- **Specific Intervention**: Concrete exercises/practices
- **Timeline**: How long will improvement take
- **Measurability**: How to track progress
- **Resources**: Books, courses, apps, therapy approaches
- **Quick Wins**: What can be improved before interview
- **Long-term Strategy**: Sustainable personality development

### 7. Interview Simulation Preparation (300+ words)
- **High-Probability Scenarios**: 5 situations they'll face
- **Your Weak Points Will Be Tested On**: Specific provocations
- **Optimal Responses**: Word-for-word examples
- **Red Flags to Avoid**: Statements that reveal weaknesses
- **Authenticity vs. Strategy**: How to be genuine while strategic

### 8. Psychiatric/Psychological Risk Assessment
- Any indicators of burnout risk
- Potential for compassion fatigue
- Stress resilience capacity
- Need for ongoing psychological support

### 9. Final Recommendation with Percentages
- **Admission Probability**: X% (based on personality fit)
- **Success in Medical School**: X%
- **Success as Practicing Physician**: X%
- **Recommended Specialties** (ranked 1-5 with rationale)
- **Go/No-Go Decision**: Clear recommendation with caveats

### 10. Personal Letter to Candidate (100+ words)
A compassionate, honest paragraph speaking directly to {user_name} about their journey.

## Critical Requirements:
- Write ENTIRELY in Hebrew (×¢×‘×¨×™×ª)
- Use professional psychological terminology with explanations
- Cite specific research when relevant (e.g., "××—×§×¨×™× ××¨××™× ×›×™...")
- Be brutally honest but constructive
- Every claim must be evidence-based from the scores
- Think like an admissions gatekeeper, not a cheerleader
- MINIMUM 1500 words

Begin the full report now in Hebrew:
"""

        return prompt

    def generate_multi_report(self, user_name, current_results, history):
        """×™×¦×™×¨×ª ×“×•×— ×›×¤×•×œ ×¢× Gemini ×•-Claude"""
        gemini_prompt = self._build_enhanced_prompt(user_name, current_results, history, "gemini")
        claude_prompt = self._build_enhanced_prompt(user_name, current_results, history, "claude")
        
        gemini_report = self._call_gemini_with_failover(gemini_prompt)
        claude_report = self._call_claude_with_detailed_errors(claude_prompt)
        
        return gemini_report, claude_report

    def _call_gemini_with_failover(self, prompt):
        """×§×¨×™××” ×œ-Gemini ×¢× Failover ××ª×§×“×"""
        if not self.gemini_keys: 
            return "âŒ ×©×’×™××”: ×œ× ×”×•×’×“×¨×• ××¤×ª×—×•×ª Gemini ×‘-Secrets. ×× × ×”×•×¡×£ GEMINI_KEY_1"
        
        for i, key in enumerate(self.gemini_keys, 1):
            try:
                model = self._discover_gemini_model(key)
                url = f"https://generativelanguage.googleapis.com/v1beta/{model}:generateContent?key={key}"
                
                payload = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {
                        "temperature": 0.7,
                        "topK": 40,
                        "topP": 0.95,
                        "maxOutputTokens": 8192  # ××§×¡×™××•× ×œ×¤×œ××©
                    }
                }
                
                res = requests.post(url, json=payload, timeout=60)
                
                if res.status_code == 200:
                    data = res.json()
                    if 'candidates' in data and len(data['candidates']) > 0:
                        text = data['candidates'][0]['content']['parts'][0]['text']
                        return text
                    else:
                        st.warning(f"âš ï¸ Gemini key #{i}: ×ª×’×•×‘×” ×¨×™×§×”")
                else:
                    error_detail = res.text[:200]
                    st.warning(f"âš ï¸ Gemini key #{i} ×”×—×–×™×¨ ×§×•×“ {res.status_code}: {error_detail}")
                    
            except requests.Timeout:
                st.warning(f"â±ï¸ Gemini key #{i}: ×ª× ×”×–××Ÿ (timeout)")
            except Exception as e:
                st.warning(f"âš ï¸ Gemini key #{i} × ×›×©×œ: {str(e)[:100]}")
                continue
        
        return "âŒ ×›×œ × ×™×¡×™×•× ×•×ª Gemini × ×›×©×œ×•. ×× × ×‘×“×•×§:\n1. ×”××¤×ª×—×•×ª ×ª×§×™× ×™× ×‘-Secrets\n2. ×™×© ×§×¨×“×™×˜ ×‘××¤×ª×—×•×ª\n3. ××™×Ÿ ×—×¡×™××ª API"

    def _call_claude_with_detailed_errors(self, prompt):
        """×§×¨×™××” ×œ-Claude ×¢× ×˜×™×¤×•×œ ×©×’×™××•×ª ××ª×§×“×"""
        if not self.claude_key: 
            return "âŒ ×©×’×™××”: ×œ× ×”×•×’×“×¨ ××¤×ª×— Claude ×‘-Secrets. ×× × ×”×•×¡×£ CLAUDE_KEY"
        
        try:
            model_id = self._discover_claude_model()
            url = "https://api.anthropic.com/v1/messages"
            headers = {
                "x-api-key": self.claude_key, 
                "anthropic-version": "2023-06-01", 
                "content-type": "application/json"
            }
            payload = {
                "model": model_id, 
                "max_tokens": 8192,  # ×”×’×“×œ×” ×œ-8K ×œ×“×•×— ××¤×•×¨×˜
                "temperature": 0.7,
                "messages": [{"role": "user", "content": prompt}]
            }
            
            res = requests.post(url, headers=headers, json=payload, timeout=90)
            
            if res.status_code == 200:
                data = res.json()
                if 'content' in data and len(data['content']) > 0:
                    return data['content'][0]['text']
                else:
                    return "âš ï¸ Claude ×”×—×–×™×¨ ×ª×’×•×‘×” ×¨×™×§×”"
            
            # ×˜×™×¤×•×œ ××¤×•×¨×˜ ×‘×©×’×™××•×ª
            error_msg = self._parse_api_error('Claude', res)
            return f"âŒ ×©×’×™××ª Claude API:\n{error_msg}\n\n×§×•×“ ×©×’×™××”: {res.status_code}\n××•×“×œ: {model_id}"
            
        except requests.Timeout:
            return "â±ï¸ ×ª×§×œ×”: Claude ×œ× ×”×’×™×‘ ×ª×•×š 90 ×©× ×™×•×ª. ×™×™×ª×›×Ÿ ×©×”×“×•×— ××¨×•×š ××“×™."
        except requests.ConnectionError:
            return "ğŸŒ ×ª×§×œ×ª ×¨×©×ª: ×œ× × ×™×ª×Ÿ ×œ×”×ª×—×‘×¨ ×œ-API ×©×œ Claude. ×‘×“×•×§ ××ª ×”×—×™×‘×•×¨ ×œ××™× ×˜×¨× ×˜."
        except Exception as e:
            return f"âš ï¸ ×©×’×™××” ×œ× ×¦×¤×•×™×” ×‘×—×™×‘×•×¨ ×œ-Claude:\n{str(e)}\n\n×¡×•×’ ×©×’×™××”: {type(e).__name__}"

    def _parse_api_error(self, provider, response):
        """× ×™×ª×•×— ××¤×•×¨×˜ ×©×œ ×©×’×™××•×ª API"""
        status = response.status_code
        try:
            detail = response.json()
            if provider == "Claude":
                msg = detail.get('error', {}).get('message', str(detail))
            else:
                msg = str(detail)
        except: 
            msg = response.text[:300]
        
        # ×©×’×™××•×ª × ×¤×•×¦×•×ª
        error_map = {
            400: "×‘×§×©×” ×©×’×•×™×” - ×”×¤×¨×•××¤×˜ ×¢×œ×•×œ ×œ×”×›×™×œ ×ª×•×›×Ÿ ×œ× ×ª×§×™×Ÿ",
            401: "××¤×ª×— API ×œ× ×ª×§×™×Ÿ ××• ×¤×’ ×ª×•×§×¤×•",
            403: "×’×™×©×” × ×“×—×ª×” - ×™×™×ª×›×Ÿ ×©×”××¤×ª×— ××™× ×• ××•×¨×©×” ×œ×©×™×¨×•×ª ×–×”",
            404: "×”××•×“×œ ×œ× × ××¦× - ×™×ª×›×Ÿ ×©×”×•× ×”×•×¡×¨ ××• ×”×©× ×©×’×•×™",
            429: "×—×¨×’×ª ×××›×¡×ª ×”×©×™××•×©. ×¤×ª×¨×•× ×•×ª:\n   - ×”××ª×Ÿ ××¡×¤×¨ ×“×§×•×ª\n   - ×©×“×¨×’ ××ª ×”×—×‘×™×œ×”\n   - ×‘×“×•×§ ×§×¨×“×™×˜",
            500: "×©×’×™××ª ×©×¨×ª ×¤× ×™××™×ª - × ×¡×” ×©×•×‘ ×‘×¢×•×“ ××¡×¤×¨ ×“×§×•×ª",
            503: "×”×©×™×¨×•×ª ××™× ×• ×–××™×Ÿ ×›×¨×’×¢ - ×ª×—×–×•×§×” ××• ×¢×•××¡"
        }
        
        error_desc = error_map.get(status, f"×©×’×™××” {status}")
        return f"{error_desc}\n\n×¤×¨×˜×™× ×˜×›× ×™×™×: {msg}"

    def create_radar_chart(self, results):
        """×™×¦×™×¨×ª ×ª×¨×©×™× ×¨×“××¨ ××©×•×¤×¨"""
        categories = [TRAIT_DICT[k] for k in results.keys()]
        user_vals = list(results.values())
        ideal_vals = [IDEAL_DOCTOR[k] for k in results.keys()]
        
        fig = go.Figure()
        
        # ×§×• ×”××™×“×™××œ
        fig.add_trace(go.Scatterpolar(
            r=ideal_vals + [ideal_vals[0]], 
            theta=categories + [categories[0]], 
            fill='toself', 
            name='ğŸ¯ ×¤×¨×•×¤×™×œ ×¨×•×¤× ××™×“×™××œ×™',
            line=dict(color='#2ECC71', width=3),
            fillcolor='rgba(46, 204, 113, 0.2)',
            opacity=0.8
        ))
        
        # ×§×• ×”××•×¢××“
        fig.add_trace(go.Scatterpolar(
            r=user_vals + [user_vals[0]], 
            theta=categories + [categories[0]], 
            fill='toself', 
            name='ğŸ“Š ×”×¤×¨×•×¤×™×œ ×©×œ×š',
            line=dict(color='#3498DB', width=4),
            fillcolor='rgba(52, 152, 219, 0.3)',
            marker=dict(size=8, color='#3498DB')
        ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True, 
                    range=[1, 5],
                    tickmode='linear',
                    tick0=1,
                    dtick=0.5,
                    gridcolor='rgba(200, 200, 200, 0.3)'
                ),
                angularaxis=dict(
                    direction='clockwise',
                    rotation=90
                )
            ),
            showlegend=True,
            title={
                'text': "××¤×ª ××™×©×™×•×ª HEXACO - ×”×©×•×•××” ×œ×™×¢×“",
                'y': 0.95,
                'x': 0.5,
                'xanchor': 'center',
                'yanchor': 'top',
                'font': dict(size=18, color='#2C3E50')
            },
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=-0.2,
                xanchor="center",
                x=0.5
            ),
            height=500
        )
        
        return fig

    def create_comparison_chart(self, results):
        """×™×¦×™×¨×ª ×ª×¨×©×™× ×¢××•×“×•×ª ××©×•×¤×¨ ×¢× ×¦×‘×¢×™× ×“×™× ××™×™×"""
        categories = [TRAIT_DICT[k] for k in results.keys()]
        user_scores = list(results.values())
        ideal_scores = [IDEAL_DOCTOR[k] for k in results.keys()]
        
        # ×¦×‘×™×¢×” ×“×™× ××™×ª ×œ×¤×™ ×¤×¢×¨×™×
        colors = []
        for trait, score in results.items():
            if trait in TRAIT_RANGES:
                ranges = TRAIT_RANGES[trait]
                if ranges["optimal_low"] <= score <= ranges["optimal_high"]:
                    colors.append('#2ECC71')  # ×™×¨×•×§ - ××¦×•×™×Ÿ
                elif score < ranges["critical_low"] or score > ranges["critical_high"]:
                    colors.append('#E74C3C')  # ××“×•× - ×‘×¢×™×™×ª×™
                else:
                    colors.append('#F39C12')  # ×›×ª×•× - ×“×•×¨×© ×©×™×¤×•×¨
            else:
                colors.append('#3498DB')  # ×›×—×•×œ - ×‘×¨×™×¨×ª ××—×“×œ
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            name='ğŸ“Š ×”×¦×™×•×Ÿ ×©×œ×š',
            x=categories,
            y=user_scores,
            marker_color=colors,
            text=[f'{s:.2f}' for s in user_scores],
            textposition='outside',
            textfont=dict(size=12, color='#2C3E50'),
            hovertemplate='<b>%{x}</b><br>×¦×™×•×Ÿ: %{y:.2f}<extra></extra>'
        ))
        
        fig.add_trace(go.Bar(
            name='ğŸ¯ ×™×¢×“ ×¨×•×¤×',
            x=categories,
            y=ideal_scores,
            marker_color='rgba(46, 204, 113, 0.6)',
            text=[f'{s:.2f}' for s in ideal_scores],
            textposition='outside',
            textfont=dict(size=12, color='#27AE60'),
            hovertemplate='<b>%{x}</b><br>×™×¢×“: %{y:.2f}<extra></extra>'
        ))
        
        fig.update_layout(
            barmode='group',
            yaxis=dict(
                range=[1, 5.5],
                title='×¦×™×•×Ÿ',
                gridcolor='rgba(200, 200, 200, 0.3)'
            ),
            xaxis=dict(
                title='',
                tickangle=-15
            ),
            title={
                'text': "×”×©×•×•××” ×›××•×ª×™×ª - ××ª×” ××•×œ ×”×™×¢×“",
                'y': 0.95,
                'x': 0.5,
                'xanchor': 'center',
                'yanchor': 'top',
                'font': dict(size=18, color='#2C3E50')
            },
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="center",
                x=0.5
            ),
            height=500,
            hovermode='x unified'
        )
        
        return fig

# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ×©×¢×•×Ÿ ×˜×•×§× ×™×
def create_token_gauge(text_content):
    """×™×•×¦×¨ ×©×¢×•×Ÿ ×•×™×–×•××œ×™ ××©×•×¤×¨ ×”××¨××” × ×™×¦×•×œ ×˜×•×§× ×™×"""
    if not text_content or not isinstance(text_content, str):
        estimated_tokens = 0
    else:
        # ×”×¢×¨×›×” ××©×•×¤×¨×ª: ×¢×‘×¨×™×ª + ×¤×™×¡×•×§
        words = len(text_content.split())
        estimated_tokens = int(words * 1.6)
    
    max_cap = 8192  # ×¢×•×“×›×Ÿ ×œ××§×¡×™××•× ×”×—×“×©
    percentage = (estimated_tokens / max_cap) * 100
    
    # ×¦×‘×¢ ×“×™× ××™ ×œ×¤×™ × ×™×¦×•×œ
    if percentage < 30:
        bar_color = "#95A5A6"  # ××¤×•×¨ - × ×™×¦×•×œ × ××•×š
    elif percentage < 60:
        bar_color = "#3498DB"  # ×›×—×•×œ - × ×™×¦×•×œ ×‘×™× ×•× ×™
    elif percentage < 85:
        bar_color = "#2ECC71"  # ×™×¨×•×§ - × ×™×¦×•×œ ×˜×•×‘
    else:
        bar_color = "#E74C3C"  # ××“×•× - ×›××¢×˜ ××œ×
    
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=estimated_tokens,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={
            'text': "× ×™×¦×•×œ ×˜×•×§× ×™× (×¢×•××§ ×•××™×›×•×ª ×”×“×•×—)",
            'font': {'size': 16, 'color': '#2C3E50'}
        },
        delta={
            'reference': max_cap * 0.6,  # ×™×¢×“ 60%
            'increasing': {'color': "#2ECC71"},
            'decreasing': {'color': "#E74C3C"}
        },
        number={
            'suffix': f" / {max_cap}",
            'font': {'size': 24, 'color': '#2C3E50'}
        },
        gauge={
            'axis': {
                'range': [None, max_cap],
                'tickwidth': 2,
                'tickcolor': "#2C3E50"
            },
            'bar': {'color': bar_color, 'thickness': 0.75},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "#BDC3C7",
            'steps': [
                {'range': [0, max_cap * 0.3], 'color': "#ECF0F1"},
                {'range': [max_cap * 0.3, max_cap * 0.6], 'color': "#D6EAF8"},
                {'range': [max_cap * 0.6, max_cap * 0.85], 'color': "#A9DFBF"},
                {'range': [max_cap * 0.85, max_cap], 'color': "#F5B7B1"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': max_cap * 0.9  # ××–×”×¨×” ×‘-90%
            }
        }
    ))
    
    fig.update_layout(
        height=280,
        margin=dict(l=20, r=20, t=60, b=20),
        paper_bgcolor="rgba(0,0,0,0)",
        font={'color': "#2C3E50", 'family': "Arial"}
    )
    
    return fig

def calculate_compatibility_score(results):
    """×—×™×©×•×‘ ××“×“ ×”×ª×××” ××ª×§×“× ×œ×¨×¤×•××”"""
    if not results:
        return 0, "××™×Ÿ × ×ª×•× ×™×"
    
    total_score = 0
    max_score = 0
    details = []
    
    for trait, score in results.items():
        if trait in TRAIT_RANGES and trait in IDEAL_DOCTOR:
            ranges = TRAIT_RANGES[trait]
            ideal = IDEAL_DOCTOR[trait]
            
            # × ×™×§×•×“ ×œ×¤×™ ×§×¨×‘×” ×œ××™×“×™××œ
            if ranges["optimal_low"] <= score <= ranges["optimal_high"]:
                points = 100  # ×¦×™×•×Ÿ ××•×©×œ×
                status = "âœ… ××¦×•×™×Ÿ"
            elif ranges["critical_low"] <= score < ranges["optimal_low"]:
                # × ×™×§×•×“ ×œ×™× ×™××¨×™ ×‘×˜×•×•×— ×”×ª×—×ª×•×Ÿ
                gap = ranges["optimal_low"] - score
                max_gap = ranges["optimal_low"] - ranges["critical_low"]
                points = 100 - (gap / max_gap * 30)  # ×¢×“ 30 × ×§×•×“×•×ª ×§× ×¡
                status = "ğŸŸ¡ ×‘×¡×“×¨"
            elif ranges["optimal_high"] < score <= ranges["critical_high"]:
                # × ×™×§×•×“ ×œ×™× ×™××¨×™ ×‘×˜×•×•×— ×”×¢×œ×™×•×Ÿ
                gap = score - ranges["optimal_high"]
                max_gap = ranges["critical_high"] - ranges["optimal_high"]
                points = 100 - (gap / max_gap * 25)  # ×¢×“ 25 × ×§×•×“×•×ª ×§× ×¡
                status = "ğŸŸ¡ ×’×‘×•×” ××¢×˜"
            else:
                points = 50  # ×¦×™×•×Ÿ ×§×¨×™×˜×™
                status = "ğŸ”´ ×‘×¢×™×™×ª×™"
            
            total_score += points
            max_score += 100
            details.append(f"{TRAIT_DICT[trait]}: {status} ({points:.0f}/100)")
    
    if max_score == 0:
        return 0, "×©×’×™××” ×‘×—×™×©×•×‘"
    
    final_percentage = int((total_score / max_score) * 100)
    details_str = "\n".join(details)
    
    return final_percentage, details_str

# ×¤×•× ×§×¦×™×•×ª ×××©×§ ×¦×™×‘×•×¨×™×•×ª
def get_multi_ai_analysis(user_name, results, history):
    """×××©×§ ×¨××©×™ ×œ×™×¦×™×¨×ª × ×™×ª×•×— AI ×›×¤×•×œ"""
    return HEXACO_Analyzer().generate_multi_report(user_name, results, history)

def get_radar_chart(results):
    """×××©×§ ×œ×™×¦×™×¨×ª ×ª×¨×©×™× ×¨×“××¨"""
    return HEXACO_Analyzer().create_radar_chart(results)

def get_comparison_chart(results):
    """×××©×§ ×œ×™×¦×™×¨×ª ×ª×¨×©×™× ×¢××•×“×•×ª"""
    return HEXACO_Analyzer().create_comparison_chart(results)

def get_compatibility_metrics(results):
    """×××©×§ ×œ×—×™×©×•×‘ ××“×“×™ ×”×ª×××”"""
    return calculate_compatibility_score(results)