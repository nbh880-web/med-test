import streamlit as st
import requests
import json
import plotly.graph_objects as go
import time
from datetime import datetime

# --- ×”×’×“×¨×•×ª ×œ×™×‘×” ×•××™×œ×•× ×™ ×ª×¨×’×•× ---
TRAIT_DICT = {
    "Honesty-Humility": "×›× ×•×ª ×•×¢× ×•×•×” (H)",
    "Emotionality": "×¨×’×©×™×•×ª (E)",
    "Extraversion": "××•×—×¦× ×•×ª (X)",
    "Agreeableness": "× ×¢×™××•×ª (A)",
    "Conscientiousness": "××¦×¤×•× ×™×•×ª (C)",
    "Openness to Experience": "×¤×ª×™×—×•×ª (O)"
}

IDEAL_DOCTOR = {
    "Honesty-Humility": 4.55, 
    "Emotionality": 3.85, 
    "Extraversion": 3.9,
    "Agreeableness": 4.3, 
    "Conscientiousness": 4.55, 
    "Openness to Experience": 3.8
}

TRAIT_RANGES = {
    "Honesty-Humility": {"critical_low": 3.5, "optimal_low": 4.2, "optimal_high": 4.9, "critical_high": 5.0},
    "Emotionality": {"critical_low": 2.8, "optimal_low": 3.6, "optimal_high": 4.1, "critical_high": 4.5},
    "Extraversion": {"critical_low": 2.5, "optimal_low": 3.6, "optimal_high": 4.2, "critical_high": 4.8},
    "Agreeableness": {"critical_low": 3.2, "optimal_low": 4.0, "optimal_high": 4.6, "critical_high": 5.0},
    "Conscientiousness": {"critical_low": 3.8, "optimal_low": 4.3, "optimal_high": 4.8, "critical_high": 5.0},
    "Openness to Experience": {"critical_low": 2.8, "optimal_low": 3.5, "optimal_high": 4.1, "critical_high": 4.7}
}

class HEXACO_System:
    def __init__(self):
        self.gemini_keys = [st.secrets.get(f"GEMINI_KEY_{i}", "").strip() for i in range(1, 4)]
        self.gemini_keys = [k for k in self.gemini_keys if k]
        self.claude_key = st.secrets.get("CLAUDE_KEY", "").strip()

    def _get_available_gemini_model(self, api_key):
        try:
            url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
            res = requests.get(url, timeout=10)
            if res.status_code == 200:
                models = [m['name'] for m in res.json().get('models', []) if 'generateContent' in m['supportedGenerationMethods']]
                for m in models: 
                    if "1.5-pro" in m: return m
                return models[0] if models else None
        except: return None

    def _call_claude(self, prompt):
        if not self.claude_key: return "âš ï¸ ××¤×ª×— Claude ×—×¡×¨ ×‘-Secrets."
        try:
            headers = {
                "x-api-key": self.claude_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            payload = {
                "model": "claude-3-5-sonnet-20240620",
                "max_tokens": 4096,
                "messages": [{"role": "user", "content": prompt}]
            }
            res = requests.post("https://api.anthropic.com/v1/messages", headers=headers, json=payload, timeout=150)
            if res.status_code == 200:
                return res.json()['content'][0]['text']
            return f"âŒ ×©×’×™××ª Claude: {res.status_code} - {res.text}"
        except Exception as e: return f"Claude Exception: {str(e)}"

    def _call_gemini_with_failover(self, prompt):
        for key in self.gemini_keys:
            model = self._get_available_gemini_model(key)
            if not model: continue
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/{model}:generateContent?key={key}"
                payload = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {"temperature": 0.85, "maxOutputTokens": 8192}
                }
                res = requests.post(url, json=payload, timeout=120)
                if res.status_code == 200:
                    return res.json()['candidates'][0]['content']['parts'][0]['text']
            except: continue
        return "âŒ ×›×œ × ×™×¡×™×•× ×•×ª ×”×¤× ×™×™×” ×œ-Gemini × ×›×©×œ×•."

    def create_radar_chart(self, results):
        categories = [TRAIT_DICT[k] for k in results.keys()]
        user_vals = list(results.values())
        ideal_vals = [IDEAL_DOCTOR[k] for k in results.keys()]
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(r=ideal_vals + [ideal_vals[0]], theta=categories + [categories[0]], fill='toself', name='ğŸ¯ ×™×¢×“ ××¡"×¨', line=dict(color='rgba(46, 204, 113, 0.8)')))
        fig.add_trace(go.Scatterpolar(r=user_vals + [user_vals[0]], theta=categories + [categories[0]], fill='toself', name='ğŸ“Š ×”×¤×¨×•×¤×™×œ ×©×œ×š', line=dict(color='#3498DB', width=4)))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[1, 5])), title="××¤×ª ××™×©×™×•×ª HEXACO")
        return fig

    def create_token_gauge(self, text_content):
        tokens = int(len(text_content.split()) * 1.5) if text_content else 0
        fig = go.Figure(go.Indicator(mode="gauge+number", value=tokens, title={'text': "×¢×•××§ × ×™×ª×•×— (Tokens)"}, gauge={'axis': {'range': [0, 8000]}, 'bar': {'color': "#2ECC71"}}))
        fig.update_layout(height=250)
        return fig

    def calculate_compatibility(self, results):
        total_points = 0
        details = []
        for trait, score in results.items():
            ranges = TRAIT_RANGES[trait]
            if ranges["optimal_low"] <= score <= ranges["optimal_high"]: points = 100
            elif score < ranges["critical_low"] or score > ranges["critical_high"]: points = 40
            else: points = 75
            total_points += points
            details.append(f"{TRAIT_DICT[trait]}: {points}/100")
        return int(total_points / 6), "\n".join(details)

    def generate_reports(self, user_name, current_results, history=[]):
        # 1. ×”×›× ×ª × ×ª×•× ×™ INPUT (×¡×¢×™×£ 1 ×‘××¤×¨×˜)
        
        # × ×™×ª×•×— ×¤×¢×¨×™× ××•×˜×•××˜×™ (1C)
        gap_analysis = ""
        for trait, score in current_results.items():
            ideal = IDEAL_DOCTOR[trait]
            diff = score - ideal
            ranges = TRAIT_RANGES[trait]
            if score < ranges["critical_low"] or score > ranges["critical_high"]:
                icon = "ğŸ”´"
                level = "×§×¨×™×˜×™"
            elif not (ranges["optimal_low"] <= score <= ranges["optimal_high"]):
                icon = "ğŸŸ¡"
                level = "×¦×•×¨×š ×©×™×¤×•×¨"
            else:
                icon = "âœ…"
                level = "×ª×§×™×Ÿ/××™×“×™××œ×™"
            gap_analysis += f"{icon} {TRAIT_DICT[trait]}: ×¦×™×•×Ÿ {score:.2f} (×¤×¢×¨ ××”××™×“×™××œ: {diff:+.2f}) - ×¡×˜×˜×•×¡: {level}\n"

        # × ×™×ª×•×— ××’××•×ª ×•×©×™× ×•×™×™× (1B, 1D)
        trends = "××™×Ÿ ×”×™×¡×˜×•×¨×™×” ×§×•×“××ª ×‘××¢×¨×›×ª ×œ××•×¢××“ ×–×”."
        if history:
            trends = "### ×©×™× ×•×™×™× ××”××‘×—×Ÿ ×”×§×•×“×:\n"
            last_res = history[-1]['results']
            for trait, score in current_results.items():
                change = score - last_res.get(trait, score)
                icon = "ğŸ“ˆ" if change > 0.05 else "ğŸ“‰" if change < -0.05 else "â¡ï¸"
                trends += f"{icon} {TRAIT_DICT[trait]}: {change:+.2f}\n"

        # 2. ×”×¨×›×‘×ª ×”×¤×¨×•××¤×˜×™× ×”××œ××™× (×¡×¢×™×£ 2 ×‘××¤×¨×˜)
        
        # × ×ª×•× ×™× ×’×•×œ××™×™× ×œ-AI
        raw_data_input = f"""
ğŸ¯ × ×™×ª×•×— ×¤×¡×™×›×•×œ×•×’×™ ××§×¦×•×¢×™ - ××•×¢××“ ×œ×¨×¤×•××”
×©× ×”××•×¢××“: {user_name}

## ğŸ“ˆ ×ª×•×¦××•×ª ××‘×—×Ÿ × ×•×›×—×™:
{json.dumps(current_results, indent=2)}

### âš ï¸ × ×™×ª×•×— ×¤×¢×¨×™× ×•××–×•×¨×™ ×¡×™×›×•×Ÿ ××—×•×©×‘:
{gap_analysis}

### ğŸ“Š × ×™×ª×•×— ××’××•×ª ×”×™×¡×˜×•×¨×™×•×ª:
{trends}
"""

        gemini_prompt = f"""
{raw_data_input}

××ª×” ×¤×¡×™×›×•×œ×•×’ ××¨×’×•× ×™ ×‘×›×™×¨ ×‘××¨×›×– ×”×¢×¨×›×” ×œ×¨×¤×•××” (××¡"×¨). 
×›×ª×•×‘ ×“×•×— ××¢××™×§ (××™× ×™××•× 1200 ××™×œ×™×) ×‘×¢×‘×¨×™×ª ×”×›×•×œ×œ:
1. ×¡×™×›×•× ×¨××©×•× ×™ (2-3 ×¤×¡×§××•×ª) - ×ª××•× ×” ×›×•×œ×œ×ª.
2. × ×™×ª×•×— ×ª×›×•× ×”-×ª×›×•× ×” - ×”×©×•×•××” ×œ×™×¢×“ ×•×”×©×¤×¢×” ×¨×¤×•××™×ª.
3. × ×™×ª×•×— ××™× ×˜×’×¨×˜×™×‘×™ - ××™×š ×”×ª×›×•× ×•×ª ××©×œ×‘×•×ª ×–×• ××ª ×–×• (×œ××©×œ ××¦×¤×•× ×™×•×ª ××•×œ × ×¢×™××•×ª).
4. ×–×™×”×•×™ ×“×¤×•×¡×™ ×ª×’×•×‘×” ×—×©×•×“×™× - ×¨×™×¦×•×™ ×—×‘×¨×ª×™ ×•×¦×™×•× ×™× ×§×™×¦×•× ×™×™×.
5. ×”××œ×¦×•×ª ××¤×•×¨×˜×•×ª ×œ×©×™×¤×•×¨ (5-7 ×”××œ×¦×•×ª) - ×ª×¨×’×™×œ×™× ×¡×¤×¦×™×¤×™×™×.
6. ×¢×¦×•×ª ×œ×¨××™×•×Ÿ ×¢× ×©×—×§×Ÿ - ×ª×¨×—×™×©×™× ×•××œ×›×•×“×•×ª.
7. ×ª×—×–×™×ª ×•×”××œ×¦×” ×¡×•×¤×™×ª - ××—×•×–×™ ×”×¦×œ×—×” ×•×ª×—×•××™ ×”×ª××—×•×ª ××•××œ×¦×™×.
"""

        claude_prompt = f"""
{raw_data_input}

You are Dr. Rachel Goldstein, a senior clinical psychologist with 20 years of experience evaluating candidates for Israeli medical schools.
×›×ª×•×‘ ×“×•×— ×‘×¢×‘×¨×™×ª (××™× ×™××•× 1500 ××™×œ×™×) ×”×›×•×œ×œ:

1. Executive Summary (3 ×¤×¡×§××•×ª).
2. Six-Factor Deep Dive (250+ ××™×œ×™× ×œ×ª×›×•× ×”!):
   A. Quantitative Analysis (score vs benchmark).
   B. Clinical Interpretation (behavioral manifestations).
   C. Real-World Scenarios (2-3 ×¡×™×˜×•××¦×™×•×ª ×¨×¤×•××™×•×ª ×¡×¤×¦×™×¤×™×•×ª).
   D. Developmental Insights.
3. Integrative Personality Synthesis (400+ ××™×œ×™×) - Configuration Analysis & Specialty Fit.
4. Validity Analysis - Social Desirability, Consistency, Confidence Level (%).
5. Development Plan (500+ ××™×œ×™×) - Timeline + Measurability.
6. Interview Preparation (300+ ××™×œ×™×) - 5 ×ª×¨×—×™×©×™× ×•×ª×©×•×‘×•×ª ××•×¤×˜×™××œ×™×•×ª ××™×œ×” ×‘××™×œ×”.
7. Risk Assessment - Burnout & Compassion fatigue.
8. Final Recommendation - Admission Probability (%), Go/No-Go Decision.
9. Personal Letter - ×¤×¡×§×” ××™×©×™×ª ×œ××•×¢××“.
"""

        return self._call_gemini_with_failover(gemini_prompt), self._call_claude(claude_prompt)

# --- ×××©×§ Streamlit ---
def main():
    st.set_page_config(page_title="HEXACO Expert - Medical Edition", layout="wide")
    system = HEXACO_System()

    # × ×™×”×•×œ × ×ª×•× ×™× ×‘-Session
    if 'results' not in st.session_state:
        st.session_state.results = {"Honesty-Humility": 4.1, "Emotionality": 3.2, "Extraversion": 3.7, "Agreeableness": 4.0, "Conscientiousness": 4.6, "Openness to Experience": 3.9}
    if 'history' not in st.session_state:
        # ×“×•×’××” ×œ×”×™×¡×˜×•×¨×™×” ×œ×¦×•×¨×š ×”×‘×“×™×§×” - × ×™×ª×Ÿ ×œ××—×•×§ ××• ×œ×”×©××™×¨
        st.session_state.history = [
            {"test_date": "01/12/2025", "results": {"Honesty-Humility": 4.0, "Emotionality": 3.5, "Extraversion": 3.7, "Agreeableness": 4.1, "Conscientiousness": 4.8, "Openness to Experience": 3.8}}
        ]

    st.title("ğŸ©º ××¢×¨×›×ª ×”×¢×¨×›×” ×¤×¡×™×›×•×œ×•×’×™×ª - × ×™×ª×•×— ××•××—×™× (××¡\"×¨)")
    st.info("×”××¢×¨×›×ª ×× ×ª×—×ª ×¤×¢×¨×™× ××”×¤×¨×•×¤×™×œ ×”××™×“×™××œ×™ ×•××’××•×ª ×”×™×¡×˜×•×¨×™×•×ª ×œ×¤× ×™ ×©×œ×™×—×” ×œ-AI.")
    
    col1, col2 = st.columns([1, 1])
    with col1:
        st.plotly_chart(system.create_radar_chart(st.session_state.results), use_container_width=True)
    with col2:
        score, details = system.calculate_compatibility(st.session_state.results)
        st.metric("××“×“ ×”×ª×××” ×›×œ×œ×™", f"{score}%")
        with st.expander("×¨××” ×¤×™×¨×•×˜ × ×™×§×•×“ ×™×‘×©"):
            st.text(details)

    if st.button("ğŸš€ ×”×¤×¢×œ × ×™×ª×•×— ××•××—×™× ××©×•×œ×‘ (Gemini + Claude)"):
        with st.spinner("×”×¤×¡×™×›×•×œ×•×’×™× ××¢×‘×“×™× ××ª ×”× ×ª×•× ×™×, ×”×¤×¢×¨×™× ×•×”××’××•×ª..."):
            gemini_rep, claude_rep = system.generate_reports("××•×¢××“ ×‘×“×™×§×”", st.session_state.results, st.session_state.history)
            
            t1, t2 = st.tabs(["ğŸ¤– ×“×•×— Gemini (××¢×©×™-××¨×’×•× ×™)", "ğŸ§  ×“×•×— Claude (×§×œ×™× ×™-××¢××™×§)"])
            with t1:
                st.markdown(gemini_rep)
                st.plotly_chart(system.create_token_gauge(gemini_rep))
            with t2:
                st.markdown(claude_rep)
                st.plotly_chart(system.create_token_gauge(claude_rep))

if __name__ == "__main__":
    main()