import streamlit as st
import requests
import json
import plotly.graph_objects as go
import time
from datetime import datetime

# --- 1. ×”×’×“×¨×•×ª ×œ×™×‘×” ×•××™×œ×•× ×™ ×ª×¨×’×•× ---
TRAIT_DICT = {
    "Honesty-Humility": "×›× ×•×ª ×•×¢× ×•×•×” (H)",
    "Emotionality": "×¨×’×©×™×•×ª (E)",
    "Extraversion": "××•×—×¦× ×•×ª (X)",
    "Agreeableness": "× ×¢×™××•×ª (A)",
    "Conscientiousness": "××¦×¤×•× ×™×•×ª (C)",
    "Openness to Experience": "×¤×ª×™×—×•×ª (O)"
}

IDEAL_DOCTOR = {
    "Honesty-Humility": 4.55, 
    "Emotionality": 3.85, 
    "Extraversion": 3.9,
    "Agreeableness": 4.3, 
    "Conscientiousness": 4.55, 
    "Openness to Experience": 3.8
}

TRAIT_RANGES = {
    "Honesty-Humility": {"critical_low": 3.5, "optimal_low": 4.2, "optimal_high": 4.9, "critical_high": 5.0},
    "Emotionality": {"critical_low": 2.8, "optimal_low": 3.6, "optimal_high": 4.1, "critical_high": 4.5},
    "Extraversion": {"critical_low": 2.5, "optimal_low": 3.6, "optimal_high": 4.2, "critical_high": 4.8},
    "Agreeableness": {"critical_low": 3.2, "optimal_low": 4.0, "optimal_high": 4.6, "critical_high": 5.0},
    "Conscientiousness": {"critical_low": 3.8, "optimal_low": 4.3, "optimal_high": 4.8, "critical_high": 5.0},
    "Openness to Experience": {"critical_low": 2.8, "optimal_low": 3.5, "optimal_high": 4.1, "critical_high": 4.7}
}

class HEXACO_System:
    def __init__(self):
        # ×©×›×‘×” 1: ×•×•×œ×™×“×¦×™×” ×•× ×™×§×•×™ ××¤×ª×—×•×ª
        self.gemini_keys = [st.secrets.get(f"GEMINI_KEY_{i}", "").strip() for i in range(1, 4)]
        self.gemini_keys = [k for k in self.gemini_keys if k]
        self.claude_key = st.secrets.get("CLAUDE_KEY", "").strip()

    # ×©×›×‘×” 3: ×¤×¢× ×•×— ×©×’×™××•×ª API (Error Parsing)
    def _parse_api_error(self, provider, response):
        status = response.status_code
        try:
            detail = response.json()
            msg = detail.get('error', {}).get('message', str(detail))
        except:
            msg = response.text[:200]
        
        error_map = {
            400: "×‘×§×©×” ×©×’×•×™×” - ×™×™×ª×›×Ÿ ×©×™×© ×ª×•×•×™× ×œ× ×ª×§×™× ×™× ××• ××•×¨×š ×—×¨×™×’.",
            401: "××¤×ª×— API ×œ× ×ª×§×™×Ÿ - ×™×© ×œ×•×•×“× ×ª×§×™× ×•×ª ×‘-Secrets.",
            429: "×—×¨×™×’×” ×××›×¡×ª ×©×™××•×© - ×”××¢×¨×›×ª ×ª×¢×‘×•×¨ ×œ××¤×ª×— ×”×‘× ××• ×©×™×© ×œ×”××ª×™×Ÿ ×“×§×”.",
            500: "×©×’×™××ª ×©×¨×ª ×¤× ×™××™×ª ×‘-AI.",
            503: "×”×©×™×¨×•×ª ×‘×¢×•××¡ ×™×ª×¨."
        }
        desc = error_map.get(status, f"×©×’×™××” {status}")
        return f"âŒ {provider}: {desc}\n×¤×¨×˜×™×: {msg}"

    def _get_available_gemini_model(self, api_key):
        try:
            url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
            res = requests.get(url, timeout=10)
            if res.status_code == 200:
                models = [m['name'] for m in res.json().get('models', []) if 'generateContent' in m['supportedGenerationMethods']]
                for m in models: 
                    if "1.5-pro" in m: return m
                return models[0] if models else None
        except: return None

    # ×©×›×‘×” 2: ×× ×’× ×•×Ÿ Failover ×œ-Gemini
    def _call_gemini_with_failover(self, prompt):
        if not self.gemini_keys: return "âŒ ×—×¡×¨×™× ××¤×ª×—×•×ª Gemini ×‘-Secrets."
        for i, key in enumerate(self.gemini_keys, 1):
            model = self._get_available_gemini_model(key)
            if not model: continue
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/{model}:generateContent?key={key}"
                payload = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {"temperature": 0.85, "maxOutputTokens": 8192}
                }
                res = requests.post(url, json=payload, timeout=120)
                if res.status_code == 200:
                    return res.json()['candidates'][0]['content']['parts'][0]['text']
                else:
                    st.warning(f"××¤×ª×— Gemini #{i} × ×›×©×œ. ×× ×¡×” ××¤×ª×— ×’×™×‘×•×™...")
            except: continue
        return "âŒ ×›×œ × ×™×¡×™×•× ×•×ª ×”×¤× ×™×™×” ×œ-Gemini × ×›×©×œ×•. ×‘×“×•×§ ×—×™×‘×•×¨ ×•×§×¨×“×™×˜."

    # ×©×›×‘×” 4: ×˜×™×¤×•×œ ××¤×•×¨×˜ ×‘-Claude
    def _call_claude(self, prompt):
        if not self.claude_key: return "âš ï¸ ××¤×ª×— Claude ×—×¡×¨ ×‘-Secrets."
        try:
            headers = {
                "x-api-key": self.claude_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            payload = {
                "model": "claude-3-5-sonnet-20240620",
                "max_tokens": 8192,
                "messages": [{"role": "user", "content": prompt}]
            }
            res = requests.post("https://api.anthropic.com/v1/messages", headers=headers, json=payload, timeout=150)
            if res.status_code == 200:
                return res.json()['content'][0]['text']
            return self._parse_api_error("Claude", res)
        except Exception as e:
            return f"âŒ ×©×’×™××” ×—×¨×™×’×” ×‘×—×™×‘×•×¨ ×œ-Claude: {str(e)}"

    def create_radar_chart(self, results):
        categories = [TRAIT_DICT[k] for k in results.keys()]
        user_vals = list(results.values())
        ideal_vals = [IDEAL_DOCTOR[k] for k in results.keys()]
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(r=ideal_vals + [ideal_vals[0]], theta=categories + [categories[0]], fill='toself', name='ğŸ¯ ×™×¢×“ ××¡"×¨', line=dict(color='rgba(46, 204, 113, 0.8)')))
        fig.add_trace(go.Scatterpolar(r=user_vals + [user_vals[0]], theta=categories + [categories[0]], fill='toself', name='ğŸ“Š ×”×¤×¨×•×¤×™×œ ×©×œ×š', line=dict(color='#3498DB', width=4)))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[1, 5])), title="××¤×ª ××™×©×™×•×ª HEXACO")
        return fig

    def create_token_gauge(self, text_content):
        tokens = int(len(text_content.split()) * 1.5) if text_content else 0
        fig = go.Figure(go.Indicator(mode="gauge+number", value=tokens, title={'text': "×¢×•××§ × ×™×ª×•×— (Tokens)"}, gauge={'axis': {'range': [0, 8000]}, 'bar': {'color': "#2ECC71"}}))
        fig.update_layout(height=250)
        return fig

    def calculate_compatibility(self, results):
        total_points = 0
        details = []
        for trait, score in results.items():
            ranges = TRAIT_RANGES[trait]
            if ranges["optimal_low"] <= score <= ranges["optimal_high"]: points = 100
            elif score < ranges["critical_low"] or score > ranges["critical_high"]: points = 40
            else: points = 75
            total_points += points
            details.append(f"{TRAIT_DICT[trait]}: {points}/100")
        return int(total_points / 6), "\n".join(details)

    # ×¤×•× ×§×¦×™×™×ª ×”×¤×§×ª ×”×“×•×—×•×ª ×¢× ×›×œ ×”×¤×¨×•××¤×˜×™× ×•×”×œ×•×’×™×§×”
    def generate_reports(self, user_name, current_results, history=[]):
        # × ×™×ª×•×— ×¤×¢×¨×™× ××•×˜×•××˜×™ (×œ×¤×™ ×¡×¢×™×£ 1C)
        gap_analysis = ""
        for trait, score in current_results.items():
            ideal = IDEAL_DOCTOR[trait]
            diff = score - ideal
            ranges = TRAIT_RANGES[trait]
            if score < ranges["critical_low"] or score > ranges["critical_high"]:
                icon, level = "ğŸ”´", "×§×¨×™×˜×™"
            elif not (ranges["optimal_low"] <= score <= ranges["optimal_high"]):
                icon, level = "ğŸŸ¡", "×¦×•×¨×š ×©×™×¤×•×¨"
            else:
                icon, level = "âœ…", "×ª×§×™×Ÿ/××™×“×™××œ×™"
            gap_analysis += f"{icon} {TRAIT_DICT[trait]}: ×¦×™×•×Ÿ {score:.2f} (×¤×¢×¨: {diff:+.2f}) - ×¡×˜×˜×•×¡: {level}\n"

        # × ×™×ª×•×— ××’××•×ª (×œ×¤×™ ×¡×¢×™×£ 1B, 1D)
        trends = "××™×Ÿ ×”×™×¡×˜×•×¨×™×” ×§×•×“××ª ×‘××¢×¨×›×ª ×œ××•×¢××“ ×–×”."
        if history:
            trends = "### ×©×™× ×•×™×™× ××”××‘×—×Ÿ ×”×§×•×“×:\n"
            last_res = history[-1]['results']
            for trait, score in current_results.items():
                change = score - last_res.get(trait, score)
                icon = "ğŸ“ˆ" if change > 0.05 else "ğŸ“‰" if change < -0.05 else "â¡ï¸"
                trends += f"{icon} {TRAIT_DICT[trait]}: {change:+.2f}\n"

        # ××™×¡×•×£ ×”-INPUT ×”×¡×•×¤×™ ×œ-AI
        raw_data_input = f"""
ğŸ¯ × ×™×ª×•×— ×¤×¡×™×›×•×œ×•×’×™ ××§×¦×•×¢×™ - ××•×¢××“ ×œ×¨×¤×•××”
×©× ×”××•×¢××“: {user_name}

## ğŸ“ˆ ×ª×•×¦××•×ª ××‘×—×Ÿ × ×•×›×—×™:
{json.dumps(current_results, indent=2)}

### ğŸ“Š × ×™×ª×•×— ××’××•×ª ×”×™×¡×˜×•×¨×™×•×ª:
{trends}

### âš ï¸ × ×™×ª×•×— ×¤×¢×¨×™× ×•××–×•×¨×™ ×¡×™×›×•×Ÿ ××—×•×©×‘:
{gap_analysis}
"""

        # ×”×¤×¨×•××¤×˜ ×”××œ× ×œ-Gemini (×œ×¤×™ ×¡×¢×™×£ 2)
        gemini_prompt = f"""
{raw_data_input}

××ª×” ×¤×¡×™×›×•×œ×•×’ ××¨×’×•× ×™ ×‘×›×™×¨ ×‘××¨×›×– ×”×¢×¨×›×” ×œ×¨×¤×•××” (××¡"×¨). 
×›×ª×•×‘ ×“×•×— ××¢××™×§ (××™× ×™××•× 1200 ××™×œ×™×) ×‘×¢×‘×¨×™×ª ×”×›×•×œ×œ:
1. ×¡×™×›×•× ×¨××©×•× ×™ (2-3 ×¤×¡×§××•×ª) - ×ª××•× ×” ×›×•×œ×œ×ª ×©×œ ×¤×¨×•×¤×™×œ ×”××•×¢××“.
2. × ×™×ª×•×— ×ª×›×•× ×”-×ª×›×•× ×” - ×”×©×•×•××” ×œ×¤×¨×•×¤×™×œ ×”××™×“×™××œ×™ ×•×“×•×’×××•×ª ××¢×•×œ× ×”×¨×¤×•××”.
3. × ×™×ª×•×— ××™× ×˜×’×¨×˜×™×‘×™ - ××™×š ×”×ª×›×•× ×•×ª ××©×œ×‘×•×ª ×–×• ××ª ×–×• (×œ××©×œ ××¦×¤×•× ×™×•×ª ××•×œ × ×¢×™××•×ª).
4. ×–×™×”×•×™ ×“×¤×•×¡×™ ×ª×’×•×‘×” ×—×©×•×“×™× - ×¨×™×¦×•×™ ×—×‘×¨×ª×™ ×•×¦×™×•× ×™× ×§×™×¦×•× ×™×™×.
5. ×”××œ×¦×•×ª ××¤×•×¨×˜×•×ª ×œ×©×™×¤×•×¨ (5-7 ×”××œ×¦×•×ª) - ××¡×˜×¨×˜×’×™×•×ª ×•×ª×¨×’×™×œ×™× ×¡×¤×¦×™×¤×™×™×.
6. ×¢×¦×•×ª ×œ×¨××™×•×Ÿ ×¢× ×©×—×§×Ÿ - ×ª×¨×—×™×©×™× ××¤×©×¨×™×™× ×•××œ×›×•×“×•×ª.
7. ×ª×—×–×™×ª ×•×”××œ×¦×” ×¡×•×¤×™×ª - ××—×•×–×™ ×”×¦×œ×—×” ×•×ª×—×•××™ ×”×ª××—×•×ª ××•××œ×¦×™×.
"""

        # ×”×¤×¨×•××¤×˜ ×”××œ× ×œ-Claude (×“"×¨ ×¨×—×œ ×’×•×œ×“×©×˜×™×™×Ÿ - ×œ×¤×™ ×¡×¢×™×£ 2)
        claude_prompt = f"""
{raw_data_input}

You are Dr. Rachel Goldstein, a senior clinical psychologist with 20 years of experience evaluating candidates for Israeli medical schools.
×›×ª×•×‘ ×“×•×— ×‘×¢×‘×¨×™×ª (××™× ×™××•× 1500 ××™×œ×™×) ×”×›×•×œ×œ:

1. Executive Summary (3 ×¤×¡×§××•×ª ×¢×©×™×¨×•×ª).
2. Six-Factor Deep Dive (×œ×¤×—×•×ª 250 ××™×œ×™× ×œ×›×œ ×ª×›×•× ×”!):
   A. Quantitative Analysis (score vs benchmark).
   B. Clinical Interpretation (behavioral manifestations in clinical settings).
   C. Real-World Scenarios (2-3 ×¡×™×˜×•××¦×™×•×ª ×¨×¤×•××™×•×ª ×¡×¤×¦×™×¤×™×•×ª).
   D. Developmental Insights (×”×× ×”×ª×›×•× ×” × ×™×ª× ×ª ×œ×©×™× ×•×™?).
3. Integrative Personality Synthesis (400+ ××™×œ×™×) - Configuration Analysis & Specialty Fit.
4. Validity Analysis - Social Desirability, Consistency, Confidence Level (%).
5. Development Plan (500+ ××™×œ×™×) - ×ª×•×›× ×™×ª ×¢×‘×•×“×” ×¢× ×™×¢×“×™× ××“×™×“×™× (Timeline + Measurability).
6. Interview Preparation (300+ ××™×œ×™×) - 5 ×ª×¨×—×™×©×™× ×•×ª×©×•×‘×•×ª ××•×¤×˜×™××œ×™×•×ª ××™×œ×” ×‘××™×œ×”.
7. Risk Assessment - × ×™×ª×•×— ×¡×™×›×•×Ÿ ×œ-Burnout ×•-Compassion fatigue.
8. Final Recommendation - Admission Probability (%), Go/No-Go Decision.
9. Personal Letter - ×¤×¡×§×” ××™×©×™×ª ×•××¢×¦×™××” ×œ××•×¢××“.
"""

        return self._call_gemini_with_failover(gemini_prompt), self._call_claude(claude_prompt)

# --- ×××©×§ Streamlit ---
def main():
    st.set_page_config(page_title="HEXACO Medical Expert System", layout="wide")
    system = HEXACO_System()

    if 'results' not in st.session_state:
        st.session_state.results = {"Honesty-Humility": 4.1, "Emotionality": 3.2, "Extraversion": 3.7, "Agreeableness": 4.0, "Conscientiousness": 4.6, "Openness to Experience": 3.9}
    if 'history' not in st.session_state:
        st.session_state.history = [{"test_date": "01/12/2025", "results": {"Honesty-Humility": 4.0, "Emotionality": 3.5, "Extraversion": 3.7, "Agreeableness": 4.1, "Conscientiousness": 4.8, "Openness to Experience": 3.8}}]

    st.title("ğŸ©º ××¢×¨×›×ª ×”×¢×¨×›×” ×¤×¡×™×›×•×œ×•×’×™×ª - × ×™×ª×•×— ××•××—×™× (××¡\"×¨)")
    
    col1, col2 = st.columns([1, 1])
    with col1:
        st.plotly_chart(system.create_radar_chart(st.session_state.results), use_container_width=True)
    with col2:
        score, details = system.calculate_compatibility(st.session_state.results)
        st.metric("××“×“ ×”×ª×××” ×›×œ×œ×™ ×œ×¨×¤×•××”", f"{score}%")
        with st.expander("×¨××” ×¤×™×¨×•×˜ × ×™×§×•×“ ×™×‘×© ×•×¤×¢×¨×™×"):
            st.text(details)

    if st.button("ğŸš€ ×”×¤×¢×œ × ×™×ª×•×— ××•××—×™× ××©×•×œ×‘ (Gemini + Claude)"):
        with st.spinner("×”×¤×¡×™×›×•×œ×•×’×™× ×× ×ª×—×™× ×¤×¢×¨×™×, ××’××•×ª ×•×ª×¨×—×™×©×™× ×§×œ×™× ×™×™×..."):
            gemini_rep, claude_rep = system.generate_reports("××•×¢××“ ×‘×“×™×§×”", st.session_state.results, st.session_state.history)
            
            t1, t2 = st.tabs(["ğŸ¤– ×“×•×— Gemini (××¨×’×•× ×™-××¢×©×™)", "ğŸ§  ×“×•×— Claude (×§×œ×™× ×™-×¢××•×§)"])
            with t1:
                st.markdown(gemini_rep)
                st.plotly_chart(system.create_token_gauge(gemini_rep))
            with t2:
                st.markdown(claude_rep)
                st.plotly_chart(system.create_token_gauge(claude_rep))

if __name__ == "__main__":
    main()